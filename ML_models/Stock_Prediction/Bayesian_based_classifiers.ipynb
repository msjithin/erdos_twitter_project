{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we attempt to predict whether trading the stock index mentioned in a tweet will yield a return greater than 1%, given the popularity, sentiment scores and other features related to the tweet. We assume that we enter into a long position in the stock index at a fixed time, $t_1$, after the tweet, and we similarly sell off the index at a later fixed time, $t_2$. \n",
    "\n",
    "We will use 2 Bayesian-based classifiers in this notebook: Naive Bayes Classifier and quadratic discriminant analysis (QDA).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Naive Bayes Classifier\n",
    "\n",
    "Recall that the Naive Bayes Model assumes that the likelihood distribution, $P(X_j|y=c)$, for each class $c$ and feature $j$ is independent. To adhere to this central assumption for the model, we will only include features that are not strongly correlated to one another. \n",
    "\n",
    "We begin by downloading the data and performing the train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/josht/Documents/tweet_stock_merged_data1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>entities_cashtags</th>\n",
       "      <th>entities_hashtags</th>\n",
       "      <th>entities_urls</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>entities_mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>Company_ticker</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>morning</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>buy_price</th>\n",
       "      <th>delta_buy</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>delta_sell</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42936</th>\n",
       "      <td>2021-02-01 10:30:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>Facebook to prompt users about personalized ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.300214</td>\n",
       "      <td>49.0</td>\n",
       "      <td>136.394886</td>\n",
       "      <td>322309.0</td>\n",
       "      <td>3.094985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>2021-06-29 02:24:46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The news that a judge threw out an antitrust l...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>FB</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>356.410000</td>\n",
       "      <td>6314.0</td>\n",
       "      <td>354.070000</td>\n",
       "      <td>300014.0</td>\n",
       "      <td>-0.656547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38152</th>\n",
       "      <td>2021-07-14 06:30:48</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$IKTSF $IKTSY - Intertek: Technically Not A Ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.428459</td>\n",
       "      <td>9852.0</td>\n",
       "      <td>146.813063</td>\n",
       "      <td>441912.0</td>\n",
       "      <td>-2.403399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11570</th>\n",
       "      <td>2020-01-29 17:41:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>Cloud, Windows sales power Microsoft earnings ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169.822678</td>\n",
       "      <td>56.0</td>\n",
       "      <td>167.811027</td>\n",
       "      <td>382796.0</td>\n",
       "      <td>-1.184560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73328</th>\n",
       "      <td>2020-10-04 15:00:16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>“Investor horizons have changed a lot in the l...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>V</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199.220118</td>\n",
       "      <td>46844.0</td>\n",
       "      <td>201.463006</td>\n",
       "      <td>316844.0</td>\n",
       "      <td>1.125834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time_stamp  entities_cashtags  entities_hashtags  \\\n",
       "42936  2021-02-01 10:30:11                  0                  0   \n",
       "19615  2021-06-29 02:24:46                  0                  0   \n",
       "38152  2021-07-14 06:30:48                  2                  3   \n",
       "11570  2020-01-29 17:41:04                  0                  0   \n",
       "73328  2020-10-04 15:00:16                  1                  0   \n",
       "\n",
       "       entities_urls  like_count  quote_count  reply_count  retweet_count  \\\n",
       "42936              2          40            4            9             19   \n",
       "19615              1           1            1            0              0   \n",
       "38152              1           0            0            0              0   \n",
       "11570              2          24            2            5             17   \n",
       "73328              2          19            1            1              9   \n",
       "\n",
       "                                                    text  entities_mentions  \\\n",
       "42936  Facebook to prompt users about personalized ad...                  0   \n",
       "19615  The news that a judge threw out an antitrust l...                  0   \n",
       "38152  $IKTSF $IKTSY - Intertek: Technically Not A Ba...                  0   \n",
       "11570  Cloud, Windows sales power Microsoft earnings ...                  0   \n",
       "73328  “Investor horizons have changed a lot in the l...                  0   \n",
       "\n",
       "       ... Company_ticker  time_of_day  morning  evening  night   buy_price  \\\n",
       "42936  ...           AAPL      morning        0        1      0  132.300214   \n",
       "19615  ...             FB        night        0        0      1  356.410000   \n",
       "38152  ...              A      morning        0        1      0  150.428459   \n",
       "11570  ...           MSFT    afternoon        1        0      0  169.822678   \n",
       "73328  ...              V    afternoon        1        0      0  199.220118   \n",
       "\n",
       "      delta_buy  sell_price  delta_sell    return  \n",
       "42936      49.0  136.394886    322309.0  3.094985  \n",
       "19615    6314.0  354.070000    300014.0 -0.656547  \n",
       "38152    9852.0  146.813063    441912.0 -2.403399  \n",
       "11570      56.0  167.811027    382796.0 -1.184560  \n",
       "73328   46844.0  201.463006    316844.0  1.125834  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_stamp', 'entities_cashtags', 'entities_hashtags', 'entities_urls',\n",
       "       'like_count', 'quote_count', 'reply_count', 'retweet_count', 'text',\n",
       "       'entities_mentions', 'created_at_user', 'followers_count',\n",
       "       'following_count', 'listed_count', 'tweet_count', 'media_type',\n",
       "       'Company_name', 'Word_count_News_agencies', 'Word_count_Henry08_pos',\n",
       "       'Word_count_Henry08_neg', 'Word_count_LM11_pos', 'Word_count_LM11_neg',\n",
       "       'Word_count_Hagenau13_pos', 'Word_count_Hagenau13_neg',\n",
       "       'Tweet_Length_characters', 'Tweet_Length_words', 'Compound_vader',\n",
       "       'Positive_vader', 'Negative_vader', 'Neutral_vader', 'Company_ticker',\n",
       "       'time_of_day', 'morning', 'evening', 'night', 'buy_price', 'delta_buy',\n",
       "       'sell_price', 'delta_sell', 'return'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724283, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579426, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144857, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the potential features we will use in our model. The last three are categorical and result from onehot encoding. We will drop the last one to avoid redundancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_features = ['like_count', 'quote_count', 'reply_count', 'retweet_count', 'followers_count', \n",
    "                      'following_count', 'listed_count', 'tweet_count', 'Word_count_News_agencies', \n",
    "                      'Word_count_Henry08_pos', 'Word_count_Henry08_neg', 'Word_count_LM11_pos', \n",
    "                      'Word_count_LM11_neg', 'Word_count_Hagenau13_pos', 'Word_count_Hagenau13_neg', \n",
    "                      'Tweet_Length_characters', 'Tweet_Length_words', 'Compound_vader', 'Positive_vader', \n",
    "                      'Negative_vader', 'Neutral_vader', 'morning', 'evening', 'night']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we employ PCA to select uncorrelated quantitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_quant_train = np.array(df_train[potential_features[:-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_qt_st = scaler.fit_transform(X_quant_train)\n",
    "phi_train = pca.fit_transform(X_qt_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579426, 21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.41037667e+01 1.30426644e+01 1.16499403e+01 1.06370918e+01\n",
      " 8.93489925e+00 5.53213363e+00 5.06115021e+00 4.43312671e+00\n",
      " 4.17097343e+00 3.90031319e+00 3.70874504e+00 3.42101766e+00\n",
      " 2.66793109e+00 2.58431616e+00 2.40773444e+00 2.35031053e+00\n",
      " 4.64879014e-01 4.49252356e-01 2.68984238e-01 2.10761571e-01\n",
      " 8.19476268e-06]\n"
     ]
    }
   ],
   "source": [
    "print(100 * pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get rid of the last five features, as they contribute little to the total variance. Since we centered and scaled the data before applying PCA, the resulting principal components are uncorrelated to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((phi_train[:, :-5], np.array(df_train[['morning', 'evening']])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579426, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_test = pca.fit_transform(scaler.fit_transform(np.array(df_test[potential_features[:-3]])))\n",
    "X_test = np.concatenate((phi_test[:, :-5], np.array(df_test[['morning', 'evening']])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144857, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(df_train[\"return\"] >= 1.0)\n",
    "y_test = np.array(df_test[\"return\"] >= 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train our Naive Bayes Classifier on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "\n",
    "NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = NB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.6225039953333126\n"
     ]
    }
   ],
   "source": [
    "acc_train = sum(pred_train == y_train)/y_train.shape[0]\n",
    "print(\"Training accuracy:\", acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6217856230627447\n"
     ]
    }
   ],
   "source": [
    "pred_test = NB.predict(X_test)\n",
    "acc_test = sum(pred_test == y_test)/y_test.shape[0]\n",
    "print(\"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis\n",
    "\n",
    "QDA assumes that the joint likelihood distribution for each class $c$ is a multivariate normal distribution: $P(X_1,\\ldots,X_m|y=c) \\sim \\mathcal{N}(\\mu_c, \\Sigma_c)$. In order to closely approximate the model assumption, we will take the logarithm of some of the features whose distributions are highly skewed to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
