{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from ediblepickle import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import subprocess\n",
    "from urllib.parse import quote\n",
    "from retrying import retry\n",
    "from time import sleep\n",
    "from ediblepickle import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = \"CSBIGB32V8U4NLBV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = 'cache'\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.mkdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checkpoint(key=lambda args, kwargs: quote(args[0]+'_'+args[1]) + '.pkl', work_dir=cache_dir)\n",
    "@retry\n",
    "def load_data(symbol,month):\n",
    "    CSV_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol='+\\\n",
    "    symbol+'&interval=1min&slice='+month+'&apikey='+API_key\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(CSV_URL)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        data = list(cr)\n",
    "        df = pd.DataFrame(data[1:],columns=data[0])\n",
    "        if len(data) < 10:\n",
    "            raise IOError(\"Failed attempt\")\n",
    "        else:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/josht/Documents/GitHub/erdos_twitter_project/data/Stock_indices/snp500_list.csv')\n",
    "tickers = df.Symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250    INTC\n",
       "251     ICE\n",
       "252     IBM\n",
       "253      IP\n",
       "254     IPG\n",
       "       ... \n",
       "371     PFE\n",
       "372      PM\n",
       "373     PSX\n",
       "374     PNW\n",
       "375     PXD\n",
       "Name: Symbol, Length: 126, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers[250: 376]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try aggregating the first one: `INTC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(tickers[250], \"year1month1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in [1,2]:\n",
    "    for string in [f'year{j}month{k}' for k in range(3-j,13)]:\n",
    "        df2 = load_data(tickers[250], string)\n",
    "        df = pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/Stock_data_250_375/\" + tickers[250] + \".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try on tickers 251 - 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICE year1month4 finished\n",
      "ICE year1month8 finished\n",
      "ICE year1month12 finished\n",
      "ICE year2month4 finished\n",
      "ICE year2month8 finished\n",
      "ICE year2month12 finished\n",
      "IBM year1month4 finished\n",
      "IBM year1month8 finished\n",
      "IBM year1month12 finished\n",
      "IBM year2month4 finished\n",
      "IBM year2month8 finished\n",
      "IBM year2month12 finished\n",
      "IP year1month4 finished\n",
      "IP year1month8 finished\n",
      "IP year1month12 finished\n",
      "IP year2month4 finished\n",
      "IP year2month8 finished\n",
      "IP year2month12 finished\n",
      "IPG year1month4 finished\n",
      "IPG year1month8 finished\n",
      "IPG year1month12 finished\n",
      "IPG year2month4 finished\n",
      "IPG year2month8 finished\n",
      "IPG year2month12 finished\n",
      "IFF year1month4 finished\n",
      "IFF year1month8 finished\n",
      "IFF year1month12 finished\n",
      "IFF year2month4 finished\n",
      "IFF year2month8 finished\n",
      "IFF year2month12 finished\n",
      "INTU year1month4 finished\n",
      "INTU year1month8 finished\n",
      "INTU year1month12 finished\n",
      "INTU year2month4 finished\n",
      "INTU year2month8 finished\n",
      "INTU year2month12 finished\n",
      "ISRG year1month4 finished\n",
      "ISRG year1month8 finished\n",
      "ISRG year1month12 finished\n",
      "ISRG year2month4 finished\n",
      "ISRG year2month8 finished\n",
      "ISRG year2month12 finished\n",
      "IVZ year1month4 finished\n",
      "IVZ year1month8 finished\n",
      "IVZ year1month12 finished\n",
      "IVZ year2month4 finished\n",
      "IVZ year2month8 finished\n",
      "IVZ year2month12 finished\n",
      "IPGP year1month4 finished\n",
      "IPGP year1month8 finished\n",
      "IPGP year1month12 finished\n",
      "IPGP year2month4 finished\n",
      "IPGP year2month8 finished\n",
      "IPGP year2month12 finished\n",
      "IQV year1month4 finished\n",
      "IQV year1month8 finished\n",
      "IQV year1month12 finished\n",
      "IQV year2month4 finished\n",
      "IQV year2month8 finished\n",
      "IQV year2month12 finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(251, 261):\n",
    "    df = load_data(tickers[i], \"year1month1\")\n",
    "    for j in [1,2]:\n",
    "        kk = 3 - j\n",
    "        for string in [f'year{j}month{k}' for k in range(3-j,13)]:\n",
    "            df2 = load_data(tickers[i], string)\n",
    "            df = pd.concat([df, df2], ignore_index=True)\n",
    "            if kk % 4 == 0:\n",
    "                print(tickers[i] + \" \" + string + \" finished\")\n",
    "            kk += 1\n",
    "    df.to_csv(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/Stock_data_250_375/\" + tickers[i] + \".csv\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're huge. Let's turn them into parquet files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(250, 261):\n",
    "    df = pd.read_csv(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/Stock_data_250_375/\" + tickers[i] + \".csv\")\n",
    "    df.to_parquet(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/Stock_data_250_375/\" + tickers[i] + \".parquet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the rest, also saving the tables as parquet files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(271, 376):\n",
    "    df = load_data(tickers[i], \"year1month1\")\n",
    "    for j in [1,2]:\n",
    "        for string in [f'year{j}month{k}' for k in range(3-j,13)]:\n",
    "            df2 = load_data(tickers[i], string)\n",
    "            df = pd.concat([df, df2], ignore_index=True)\n",
    "    df.to_parquet(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/Stock_data_250_375/\" + tickers[i] + \".parquet\")\n",
    "    print(tickers[i] + \" finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers[271]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Problematic_indices.append([270, \"KSU\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[270, 'KSU']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Problematic_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Problematic_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/Stock_data_250_375/JNPR.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-17 16:14:00</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.12</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-17 16:11:00</td>\n",
       "      <td>31.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-17 16:06:00</td>\n",
       "      <td>31.95</td>\n",
       "      <td>31.99</td>\n",
       "      <td>31.95</td>\n",
       "      <td>31.99</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-17 16:03:00</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.12</td>\n",
       "      <td>6479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-17 16:02:00</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.12</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194547</th>\n",
       "      <td>2019-11-29 09:35:00</td>\n",
       "      <td>23.8059087869</td>\n",
       "      <td>23.8060031799</td>\n",
       "      <td>23.7681515961</td>\n",
       "      <td>23.7681515961</td>\n",
       "      <td>1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194548</th>\n",
       "      <td>2019-11-29 09:34:00</td>\n",
       "      <td>23.8245985963</td>\n",
       "      <td>23.83422668</td>\n",
       "      <td>23.8059087869</td>\n",
       "      <td>23.8247873823</td>\n",
       "      <td>3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194549</th>\n",
       "      <td>2019-11-29 09:33:00</td>\n",
       "      <td>23.7870301915</td>\n",
       "      <td>23.8247873823</td>\n",
       "      <td>23.7823105426</td>\n",
       "      <td>23.8247873823</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194550</th>\n",
       "      <td>2019-11-29 09:32:00</td>\n",
       "      <td>23.8106284357</td>\n",
       "      <td>23.8247873823</td>\n",
       "      <td>23.7917498403</td>\n",
       "      <td>23.7917498403</td>\n",
       "      <td>2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194551</th>\n",
       "      <td>2019-11-29 09:31:00</td>\n",
       "      <td>23.6926372145</td>\n",
       "      <td>23.7964694892</td>\n",
       "      <td>23.6831979168</td>\n",
       "      <td>23.7964694892</td>\n",
       "      <td>38166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194552 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time           open           high            low  \\\n",
       "0       2021-11-17 16:14:00          32.12          32.12          32.12   \n",
       "1       2021-11-17 16:11:00           31.7           31.7           31.7   \n",
       "2       2021-11-17 16:06:00          31.95          31.99          31.95   \n",
       "3       2021-11-17 16:03:00          32.12          32.12          32.12   \n",
       "4       2021-11-17 16:02:00          32.12          32.12           32.0   \n",
       "...                     ...            ...            ...            ...   \n",
       "194547  2019-11-29 09:35:00  23.8059087869  23.8060031799  23.7681515961   \n",
       "194548  2019-11-29 09:34:00  23.8245985963    23.83422668  23.8059087869   \n",
       "194549  2019-11-29 09:33:00  23.7870301915  23.8247873823  23.7823105426   \n",
       "194550  2019-11-29 09:32:00  23.8106284357  23.8247873823  23.7917498403   \n",
       "194551  2019-11-29 09:31:00  23.6926372145  23.7964694892  23.6831979168   \n",
       "\n",
       "                close volume  \n",
       "0               32.12   2194  \n",
       "1                31.7    200  \n",
       "2               31.99   1061  \n",
       "3               32.12   6479  \n",
       "4               32.12   1275  \n",
       "...               ...    ...  \n",
       "194547  23.7681515961   1934  \n",
       "194548  23.8247873823   3772  \n",
       "194549  23.8247873823   2376  \n",
       "194550  23.7917498403   2236  \n",
       "194551  23.7964694892  38166  \n",
       "\n",
       "[194552 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = \"CSBIGB32V8U4NLBV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = subprocess.Popen('pwd', stdout=subprocess.PIPE)\n",
    "cmd_out, cmd_err = cmd.communicate()\n",
    "local_path = os.fsdecode(cmd_out).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = 'cache'\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.mkdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checkpoint(key=lambda args, kwargs: quote(args[0]+'_'+args[1]) + '.pkl', work_dir=cache_dir)\n",
    "@retry\n",
    "def load_data(symbol,month):\n",
    "    CSV_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol='+\\\n",
    "    symbol+'&interval=1min&slice='+month+'&apikey='+API_key\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(CSV_URL)\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        data = list(cr)\n",
    "        df = pd.DataFrame(data[1:],columns=data[0])\n",
    "        if len(data) < 10:\n",
    "            raise IOError(\"Failed attempt\")\n",
    "        else:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/josht/Documents/GitHub/erdos_twitter_project/data/Stock_indices/snp500_list.csv')\n",
    "tickers = df.Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTC'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.fsencode(local_path+'/cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/cache/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(symbol):\n",
    "    df = pd.read_pickle(local_path+'/cache/'+symbol+'_year1month2.pkl')\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.startswith(f'{symbol}_') and filename.endswith('.pkl'):\n",
    "            if '_year1month2.pkl' in filename : continue  # we need to skip this file to avoid double counting\n",
    "            df = pd.concat([df,pd.read_pickle(local_path+'/cache/'+filename)])\n",
    "            #print(len(df),filename) \n",
    "            # uncomment the above line if you want some output just so that you know the code is running as expected\n",
    "            os.remove(local_path+'/cache/'+filename)\n",
    "            \n",
    "        df.to_csv(local_path+'/cache/'+f'{symbol}.csv',index=False)\n",
    "    os.remove(local_path+\"cache/\"+symbol+'_year1month2.pkl') \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/cache/INTC_year1month2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-73f9dea0dd73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/cache/INTC_year1month2.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/cache/INTC_year1month2.pkl'"
     ]
    }
   ],
   "source": [
    "pd.read_pickle(local_path+'/cache/INTC_year1month2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fc3933cddcdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf'year{j}month{k}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ticker in tickers[:1]:  #set the ticker range here\n",
    "    for j in [1,2]:\n",
    "        for string in [f'year{j}month{k}' for k in range(1,13)]:\n",
    "            load_data(ticker,string)\n",
    "            sleep(1)\n",
    "            \n",
    "    aggregate(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year1month1\n",
      "year1month2\n",
      "year1month3\n",
      "year1month4\n",
      "year1month5\n",
      "year1month6\n",
      "year1month7\n",
      "year1month8\n",
      "year1month9\n",
      "year1month10\n",
      "year1month11\n",
      "year1month12\n",
      "year2month1\n",
      "year2month2\n",
      "year2month3\n",
      "year2month4\n",
      "year2month5\n",
      "year2month6\n",
      "year2month7\n",
      "year2month8\n",
      "year2month9\n",
      "year2month10\n",
      "year2month11\n",
      "year2month12\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers[0:1]:  #set the ticker range here\n",
    "    for j in [1,2]:\n",
    "        for string in [f'year{j}month{k}' for k in range(1,13)]:\n",
    "            print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_data(\"TSLA\", \"year1month1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-17 20:00:00</td>\n",
       "      <td>1087.75</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>1087.6</td>\n",
       "      <td>1087.9999</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-17 19:59:00</td>\n",
       "      <td>1087.45</td>\n",
       "      <td>1087.96</td>\n",
       "      <td>1087.45</td>\n",
       "      <td>1087.6001</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-17 19:58:00</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>1087.47</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>1087.47</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-17 19:55:00</td>\n",
       "      <td>1086.79</td>\n",
       "      <td>1086.79</td>\n",
       "      <td>1086.79</td>\n",
       "      <td>1086.79</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-17 19:54:00</td>\n",
       "      <td>1087.35</td>\n",
       "      <td>1087.35</td>\n",
       "      <td>1087.35</td>\n",
       "      <td>1087.35</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17465</th>\n",
       "      <td>2021-10-19 04:05:00</td>\n",
       "      <td>875.7</td>\n",
       "      <td>876.0</td>\n",
       "      <td>875.5</td>\n",
       "      <td>875.5</td>\n",
       "      <td>2210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17466</th>\n",
       "      <td>2021-10-19 04:04:00</td>\n",
       "      <td>875.61</td>\n",
       "      <td>876.0</td>\n",
       "      <td>875.61</td>\n",
       "      <td>876.0</td>\n",
       "      <td>1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17467</th>\n",
       "      <td>2021-10-19 04:03:00</td>\n",
       "      <td>875.8</td>\n",
       "      <td>875.8</td>\n",
       "      <td>875.8</td>\n",
       "      <td>875.8</td>\n",
       "      <td>1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17468</th>\n",
       "      <td>2021-10-19 04:02:00</td>\n",
       "      <td>875.7</td>\n",
       "      <td>875.7</td>\n",
       "      <td>875.7</td>\n",
       "      <td>875.7</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17469</th>\n",
       "      <td>2021-10-19 04:01:00</td>\n",
       "      <td>874.7</td>\n",
       "      <td>874.7</td>\n",
       "      <td>874.7</td>\n",
       "      <td>874.7</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17470 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time     open     high      low      close volume\n",
       "0      2021-11-17 20:00:00  1087.75   1088.0   1087.6  1087.9999   2581\n",
       "1      2021-11-17 19:59:00  1087.45  1087.96  1087.45  1087.6001   1407\n",
       "2      2021-11-17 19:58:00   1087.0  1087.47   1087.0    1087.47   1160\n",
       "3      2021-11-17 19:55:00  1086.79  1086.79  1086.79    1086.79    762\n",
       "4      2021-11-17 19:54:00  1087.35  1087.35  1087.35    1087.35    675\n",
       "...                    ...      ...      ...      ...        ...    ...\n",
       "17465  2021-10-19 04:05:00    875.7    876.0    875.5      875.5   2210\n",
       "17466  2021-10-19 04:04:00   875.61    876.0   875.61      876.0   1764\n",
       "17467  2021-10-19 04:03:00    875.8    875.8    875.8      875.8   1602\n",
       "17468  2021-10-19 04:02:00    875.7    875.7    875.7      875.7   1110\n",
       "17469  2021-10-19 04:01:00    874.7    874.7    874.7      874.7    737\n",
       "\n",
       "[17470 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"/Users/josht/Documents/GitHub/erdos_twitter_project/Stock_data_get/tesla_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
